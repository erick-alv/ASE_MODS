params:
  seed: -1

  algo:
    name: common #inherits a2c_continuous

  model:
    name: continuous_a2c_logstd

  network:
    name: common #inherits actor_critic
    separate: True #What does this parameter?: When true different MLP for the actor and critic are created. When false one single MLP for both

    space:
      continuous:
        mu_activation: None
        sigma_activation: None
        mu_init:
          name: default
        sigma_init:
          name: const_initializer
          val: -2.5 #exp(-3.506) = 0.02; exp(-2.9)=0.05=> more exploration
        fixed_sigma: True
        learn_sigma: False

    mlp:
      units: [1024, 512]
      activation: relu
      d2rl: False

      initializer:
        name: default
      regularizer:
        name: None

  load_checkpoint: False

  config:
    name: HumanoidImitation
    env_name: rlgpu
    multi_gpu: False
    mixed_precision: False
    normalize_input: True #rsl_rl is not using this
    normalize_value: True #rsl_rl is not using this
    reward_shaper:
      scale_value: 1
    normalize_advantage: True
    gamma: 0.97 #0.97 used in QuestSim
    tau: 0.95 #this is the lambda from GAE. 0.95 used in QuestSim
    learning_rate: 2e-5 # 1e-4 used in QuestSim
    lr_schedule: constant #in QuestSim there is no mention that lr is modified
    score_to_win: 20000 #actually not being used
    max_epochs: 10000
    save_best_after: 2000
    save_frequency: 2000
    save_intermediate: True
    print_stats: True
    entropy_coef: 0.0 #TODO ? docu suggests 0.0 other max to 0.01; questsim suggres explration noise 0.03; but is not clear if this is the same implementation of that noise
    grad_norm: 1.0 #not mentioned in QuestSim; but used in rsl_rl; uses e.0
    truncate_grads: True #not mentioned in QuestSim; but used in rsl_rl
    ppo: True
    e_clip: 0.2 #0.2 used in QuestSim
    horizon_length: 15 #15 used in QuestSim
    minibatch_size: 2048 #7680 #15000 used in QuestSim (gives the 4 minibatches)
    mini_epochs: 5 #5 used in QuestSim
    critic_coef: 5 #not mentioned directly in QuestSim; 1 is default in rsl_rl implementation
    clip_value: True
    #seq_len: 4 #This parameter is just used for rnn and therefore can be ignored in our case
    #bounds_loss_coef: 0 #not mentioned directly in QuestSim; not used in rsl_rl implementation -> Commented out so is None in code and therefore not used